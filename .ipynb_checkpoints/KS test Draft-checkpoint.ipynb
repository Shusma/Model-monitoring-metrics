{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolmogorov-Smirnov test\n",
    "\n",
    "During Model Validation this criterion shows to what extent the model separates the actual good borrowers from the actual bad borrowers.\n",
    "\n",
    "It is measured by looking at the cumulative distributions of actual bad borrowers and actual good borrowers with respect to the estimated probabilities of being good and bad by our model. \n",
    "\n",
    "**KS for this case is the maximum difference between the cumulative distribution functions of bad and good borrowers with respect to predicted probabilities.**\n",
    "\n",
    "$$ KS =  max \\Big\\{(\\text{Cumulative % Event}) - (\\text{Cumulative % Non-Event})\\Big\\}  $$\n",
    "\n",
    "where Event ($Y = 1$) = Default (ie. 'Bad' Borrowers) and Non-event ($Y = 0$) = Non-Default ('Good' Borrowers)\n",
    "### Method:\n",
    "- You need to have two variables before calculating KS. One is the binary dependent variable. Second is predicted probability score which is generated from statistical model.\n",
    "- Sort the variables by the predicted probability score.\n",
    "- Calculate the cumulative % of actual 'bad' and 'good' borrowers (default/non-default) then compute the difference between these two cumulative distributions.\n",
    "- KS is where the difference is maximum\n",
    "\n",
    "The greater this difference the better the model.\n",
    "\n",
    "Perfect model -> Maximum distance KS = 1, Predicting by chance -> Almost no distance KS = 0\n",
    "\n",
    "\n",
    "In order to perform Model Performance Monitoring, KS-test can be used to measure the predictive power of the scorecard on the Recent population and compares this performance to that of Development population.\n",
    "\n",
    "<p class='lead'> Code Example using the LoanEE2 Dataset: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/ProtectedFeaturesLoanEE2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select favourable and unfavourable outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='Default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MonthlyPayment'].fillna((data['MonthlyPayment'].mean()), inplace=True)\n",
    "data['ExpectedLoss'].fillna((data['ExpectedLoss'].mean()), inplace=True)\n",
    "data['ProbabilityOfDefault'].fillna((data['ProbabilityOfDefault'].mean()), inplace=True)\n",
    "data['DebtToIncome'].fillna((data['DebtToIncome'].mean()), inplace=True)\n",
    "data['FreeCash'].fillna((data['FreeCash'].mean()), inplace=True)\n",
    "data['LossGivenDefault'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(columns=['Young','Unnamed: 0', 'Unnamed: 0.1', 'Default'])\n",
    "y=data['Default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_reg.predict(X_test)\n",
    "y_pred_prob = logistic_reg.predict_proba(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.7589824427895853\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model:\", logistic_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-values with Logistic Regression\n",
    "\n",
    "### Significance/Hypothesis Testing \n",
    "\n",
    "#### Null Hyposthesis Significance Testing (NHST)\n",
    "A statistical hypothesis is an assumption about a population which may or may not be true. Hypothesis testing is a set of formal procedures used by statisticians to either accept or reject statistical hypotheses. Statistical hypotheses are of two types: \n",
    "\n",
    "eg: if we have a hypothesis that people with gene X - eat a different amount of calories..\n",
    "\n",
    "- **Null Hypothesis (H_0)**: says that this gene has no difference or effect \n",
    "\n",
    "- **Alternate Hypothesis (H_a)**: agrees with our original hypothesis\n",
    "\n",
    "P-value: probability value \n",
    "\n",
    "In a nut-shell p-values indicate how \"rare\" your data is by telling you the probability of getting data that's as extreme as the data you observed if the null hypothesis were true. Typically p-values depict the two-sided tails of a distribution. This allows us to reject our null hypothesis if our value is signifacntly higher or lower than the mean. \n",
    "\n",
    "*ONE COMMON MISCONCEPTION of a p-value is that it can tell you the probability that the null hypothesis is true* **IT CAN'T!!**\n",
    "\n",
    "**Conventionally if a p-value is lower than 0.05 five we conclude that the coefficient of that variable is *statistically significant.***\n",
    "\n",
    "Computing [p-values](http://rspeare.blogspot.com/2017/10/p-values-for-logistic-regression.html) for each and every coefficient fit by a sklearn logistic regression model - boils down to computing the Log-likelihood $\\mathcal{L}$, the Fisher Information Matrix $F$ and the Cramer-Rao bound. \n",
    "\n",
    "$$ \\frac{-\\partial^2\\mathcal{L}}{\\partial\\beta_i\\partial\\beta_j} = F_{ij} $$\n",
    "$$ Var[\\beta_i] \\geq F_{ii}^{-1} $$\n",
    "\n",
    "Which for logistic regression, gives us:\n",
    "\n",
    "$$ P(y|x) = \\frac{1}{1 + e^{-\\beta.x}} $$\n",
    "\n",
    "$$ \\mathcal{L} = \\sum^{N}_{n=1} y_n log(P(y_n|x_n)) + (1-y_n)log(1-P(y_n|x_n))$$\n",
    "\n",
    "$$ F_{ij} = \\sum^N_{n=1} \\frac{x_{ni}x_{nj}}{2 + 2 cosh(\\beta.x)} $$ (*no idea how to prove $F_{ij}$*)\n",
    "\n",
    "```decision_function(X)``` refers to $\\beta.x$\n",
    "\n",
    "> ```sklearn``` Predict confidence scores for samples.\n",
    "The confidence score for a sample is the signed distance of that sample to the hyperplane.\n",
    "\n",
    "\n",
    "Normally one assumes each $\\beta$ coefficient is normally distributed, with mean $\\hat{\\beta}$ -- the maximum likelihood estimate, which in the case of logistic regression is wherever you stop numerically since there is no analytical solution.\n",
    "\n",
    "Variance: $ \\sigma_{\\beta_i} \\approx F_{ii}^{-1}$\n",
    "\n",
    "Coefficient: $ \\beta \\sim \\mathcal{N}(\\hat{\\beta_i}, F_{ii}^{-1})$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P values for sklearn logistic regression.\n",
    "# Class to display p-values for logistic regression in sklearn.\n",
    "\n",
    "from sklearn import linear_model\n",
    "import scipy.stats as stat\n",
    "\n",
    "class LogisticRegression_with_p_values:\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.model = linear_model.LogisticRegression(*args,**kwargs)#,**args)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.model.fit(X,y)\n",
    "        \n",
    "        #### Get p-values for the fitted model ####\n",
    "        denom = (2.0 * (1.0 + np.cosh(self.model.decision_function(X))))\n",
    "        denom = np.tile(denom,(X.shape[1],1)).T\n",
    "        F_ij = np.dot((X / denom).T,X) ## Fisher Information Matrix\n",
    "        noisy_F_ij = F_ij+0.00001*np.random.rand(F_ij.shape[0],F_ij.shape[1])\n",
    "        Cramer_Rao = np.linalg.inv(noisy_F_ij) ## Inverse Information Matrix\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = self.model.coef_[0] / sigma_estimates # z-score for each model coefficient\n",
    "        p_values = [stat.norm.sf(abs(x)) * 2 for x in z_scores] ### two tailed test for p-values\n",
    "        \n",
    "        self.coef_ = self.model.coef_\n",
    "        self.intercept_ = self.model.intercept_\n",
    "        self.p_values = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_p = LogisticRegression_with_p_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = X_train.columns.values\n",
    "summary_table_p = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "summary_table_p['Coefficients'] = np.transpose(logistic_reg_p.coef_)\n",
    "summary_table_p.index = summary_table_p.index + 1\n",
    "summary_table_p.loc[0] = ['Intercept', logistic_reg_p.intercept_[0]]\n",
    "summary_table_p = summary_table_p.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = logistic_reg_p.p_values\n",
    "p_values = np.append(np.nan, np.array(p_values))\n",
    "summary_table_p['p_values'] = p_values\n",
    "summary_table_p['p_values'] = summary_table_p['p_values'].round(decimals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistically significant features\n",
    "Now we can select independent variables based on them by only retaining the variables with coefficients that are statistically significant.\n",
    "\n",
    "It's good to remember that each original independent variable is represented by several dummy variables. If two or more of the dummy variables representing one original independent variable are statistically significant it would be best to retain all dummy variables that represent that original independent variable in the final model.\n",
    "\n",
    "**Conventionally if a p-value is lower than 0.05 five we conclude that the coefficient of that variable is *statistically significant.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>p_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AppliedAmount</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FreeCash</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.00025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IncomeFromChildSupport</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IncomeFromFamilyAllowance</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IncomeFromLeavePay</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IncomeFromPension</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.03505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IncomeFromPrincipalEmployer</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IncomeFromSocialWelfare</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.00090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IncomeOther</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IncomeTotal</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LoanDuration</td>\n",
       "      <td>-0.011831</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MonthlyPayment</td>\n",
       "      <td>-0.004624</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature name  Coefficients  p_values\n",
       "2                 AppliedAmount      0.000229   0.00000\n",
       "6                      FreeCash     -0.000234   0.00025\n",
       "7        IncomeFromChildSupport      0.001838   0.00000\n",
       "8     IncomeFromFamilyAllowance      0.001853   0.00000\n",
       "9            IncomeFromLeavePay      0.001297   0.00000\n",
       "10            IncomeFromPension      0.000495   0.03505\n",
       "11  IncomeFromPrincipalEmployer      0.000884   0.00000\n",
       "12      IncomeFromSocialWelfare      0.002019   0.00090\n",
       "13                  IncomeOther      0.000887   0.00000\n",
       "14                  IncomeTotal     -0.000888   0.00000\n",
       "16                 LoanDuration     -0.011831   0.00000\n",
       "18               MonthlyPayment     -0.004624   0.00000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table_p[summary_table_p['p_values'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.7589824427895853\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model:\", logistic_reg_p.model.score(X_test, y_test)) #should be the same as previous logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs = pd.DataFrame({'y_test':y_test, 'y_hat_test_proba':y_pred_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 0.5 \n",
    "df_actual_predicted_probs['y_hat_test'] = np.where(df_actual_predicted_probs['y_hat_test_proba'] > tr, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs = df_actual_predicted_probs.sort_values('y_hat_test_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs = df_actual_predicted_probs.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cumulative number of all observations, of 'bad' and 'good' borrowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the cumulative number of all observations.\n",
    "# We use the new index for that. Since indexing in python starts from 0, we add 1 to each index.\n",
    "df_actual_predicted_probs['Cumulative N Population'] = df_actual_predicted_probs.index + 1\n",
    "\n",
    "# We calculate cumulative number of 'bad', which is the cumulative sum of the column with actual observations.\n",
    "df_actual_predicted_probs['Cumulative N Bad'] = df_actual_predicted_probs['y_test'].cumsum()\n",
    "\n",
    "# We calculate cumulative number of 'good', which is\n",
    "# the difference between the cumulative number of all observations and cumulative number of 'good' for each row.\n",
    "df_actual_predicted_probs['Cumulative N Good'] = df_actual_predicted_probs['Cumulative N Population'] - df_actual_predicted_probs['y_test'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_hat_test_proba</th>\n",
       "      <th>y_hat_test</th>\n",
       "      <th>Cumulative N Population</th>\n",
       "      <th>Cumulative N Bad</th>\n",
       "      <th>Cumulative N Good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111078</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159244</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182868</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  y_test  y_hat_test_proba  y_hat_test  Cumulative N Population  \\\n",
       "0   4740       0          0.111078           0                        1   \n",
       "1   3712       0          0.159244           0                        2   \n",
       "2   3617       0          0.162393           0                        3   \n",
       "3   6821       0          0.181421           0                        4   \n",
       "4   6649       1          0.182868           0                        5   \n",
       "\n",
       "   Cumulative N Bad  Cumulative N Good  \n",
       "0                 0                  1  \n",
       "1                 0                  2  \n",
       "2                 0                  3  \n",
       "3                 0                  4  \n",
       "4                 1                  4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cumulative % of all observations, of 'bad' and 'good' borrowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the cumulative percentage of all observations.\n",
    "df_actual_predicted_probs['Cumulative Perc Population'] = df_actual_predicted_probs['Cumulative N Population'] / (df_actual_predicted_probs.shape[0])\n",
    "\n",
    "# We calculate cumulative percentage of 'bad'.\n",
    "df_actual_predicted_probs['Cumulative Perc Bad'] = df_actual_predicted_probs['Cumulative N Bad'] / df_actual_predicted_probs['y_test'].sum()\n",
    "\n",
    "# We calculate the cumulative percentage of 'good'.\n",
    "df_actual_predicted_probs['Cumulative Perc Good'] = df_actual_predicted_probs['Cumulative N Good'] / (df_actual_predicted_probs.shape[0] - df_actual_predicted_probs['y_test'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_hat_test_proba</th>\n",
       "      <th>y_hat_test</th>\n",
       "      <th>Cumulative N Population</th>\n",
       "      <th>Cumulative N Bad</th>\n",
       "      <th>Cumulative N Good</th>\n",
       "      <th>Cumulative Perc Population</th>\n",
       "      <th>Cumulative Perc Bad</th>\n",
       "      <th>Cumulative Perc Good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111078</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159244</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182868</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  y_test  y_hat_test_proba  y_hat_test  Cumulative N Population  \\\n",
       "0   4740       0          0.111078           0                        1   \n",
       "1   3712       0          0.159244           0                        2   \n",
       "2   3617       0          0.162393           0                        3   \n",
       "3   6821       0          0.181421           0                        4   \n",
       "4   6649       1          0.182868           0                        5   \n",
       "\n",
       "   Cumulative N Bad  Cumulative N Good  Cumulative Perc Population  \\\n",
       "0                 0                  1                    0.000054   \n",
       "1                 0                  2                    0.000109   \n",
       "2                 0                  3                    0.000163   \n",
       "3                 0                  4                    0.000217   \n",
       "4                 1                  4                    0.000272   \n",
       "\n",
       "   Cumulative Perc Bad  Cumulative Perc Good  \n",
       "0             0.000000              0.000071  \n",
       "1             0.000000              0.000143  \n",
       "2             0.000000              0.000214  \n",
       "3             0.000000              0.000286  \n",
       "4             0.000227              0.000286  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Kolmogorov-Smirnov coefficient (KS)\n",
    "\n",
    "**KS for this case is the maximum difference between the cumulative distribution functions of bad and good borrowers with respect to predicted probabilities.**\n",
    "\n",
    "The greater this difference the better the model.\n",
    "\n",
    "Perfect model -> Maximum distance KS = 1, Predicting by chance -> Almost no distance KS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs['Individual KS'] = abs(df_actual_predicted_probs['Cumulative Perc Bad'] - df_actual_predicted_probs['Cumulative Perc Good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_hat_test_proba</th>\n",
       "      <th>y_hat_test</th>\n",
       "      <th>Cumulative N Population</th>\n",
       "      <th>Cumulative N Bad</th>\n",
       "      <th>Cumulative N Good</th>\n",
       "      <th>Cumulative Perc Population</th>\n",
       "      <th>Cumulative Perc Bad</th>\n",
       "      <th>Cumulative Perc Good</th>\n",
       "      <th>Individual KS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111078</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159244</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182868</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  y_test  y_hat_test_proba  y_hat_test  Cumulative N Population  \\\n",
       "0   4740       0          0.111078           0                        1   \n",
       "1   3712       0          0.159244           0                        2   \n",
       "2   3617       0          0.162393           0                        3   \n",
       "3   6821       0          0.181421           0                        4   \n",
       "4   6649       1          0.182868           0                        5   \n",
       "\n",
       "   Cumulative N Bad  Cumulative N Good  Cumulative Perc Population  \\\n",
       "0                 0                  1                    0.000054   \n",
       "1                 0                  2                    0.000109   \n",
       "2                 0                  3                    0.000163   \n",
       "3                 0                  4                    0.000217   \n",
       "4                 1                  4                    0.000272   \n",
       "\n",
       "   Cumulative Perc Bad  Cumulative Perc Good  Individual KS  \n",
       "0             0.000000              0.000071       0.000071  \n",
       "1             0.000000              0.000143       0.000143  \n",
       "2             0.000000              0.000214       0.000214  \n",
       "3             0.000000              0.000286       0.000286  \n",
       "4             0.000227              0.000286       0.000059  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Kolmogorov-Smirnov')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot KS\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(df_actual_predicted_probs['y_hat_test_proba'], df_actual_predicted_probs['Cumulative Perc Bad'], color = 'r', label='Cumulative % Bad')\n",
    "plt.plot(df_actual_predicted_probs['y_hat_test_proba'], df_actual_predicted_probs['Cumulative Perc Good'], color = 'g', label='Cumulative % Good')\n",
    "\n",
    "x = df_actual_predicted_probs['y_hat_test_proba']\n",
    "    \n",
    "y1 = df_actual_predicted_probs['Cumulative Perc Bad']\n",
    "y2 = df_actual_predicted_probs['Cumulative Perc Good']\n",
    "    \n",
    "ind_max = np.argmax((y1-y2)**2)\n",
    "\n",
    "# plt.axvline(x[ind_max], color=\"blue\", linestyle=\"dashed\", alpha=0.4)\n",
    "plt.plot([x[ind_max], x[ind_max]], [y2[ind_max], y1[ind_max]], color=\"blue\")\n",
    "\n",
    "plt.xlabel('Estimated Probability')\n",
    "plt.ylabel('Cumulative %')\n",
    "plt.legend()\n",
    "plt.title('Kolmogorov-Smirnov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate KS from the data. It is the maximum of the difference between the cumulative percentage of 'bad'\n",
    "and the cumulative percentage of 'good'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24890443314778865"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KS = max(df_actual_predicted_probs['Individual KS'])\n",
    "KS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test(y_actual, y_pred_prob, classifier_threshold):\n",
    "    df_actual_pred_probs = pd.DataFrame({'y_actual':y_actual, 'y_hat_test_proba':y_pred_prob})\n",
    "    df_actual_pred_probs['y_hat_test'] = np.where(df_actual_pred_probs['y_hat_test_proba'] > tr, 1, 0)\n",
    "    df_actual_pred_probs = df_actual_pred_probs.sort_values('y_hat_test_proba')\n",
    "    df_actual_pred_probs = df_actual_pred_probs.reset_index()\n",
    "    \n",
    "    df_actual_pred_probs['Cumulative N Population'] = df_actual_pred_probs.index + 1\n",
    "    df_actual_pred_probs['Cumulative N Bad'] = df_actual_pred_probs['y_actual'].cumsum()\n",
    "    df_actual_pred_probs['Cumulative N Good'] = df_actual_pred_probs['Cumulative N Population'] - df_actual_pred_probs['y_actual'].cumsum()\n",
    "\n",
    "    df_actual_pred_probs['Cumulative Perc Population'] = df_actual_pred_probs['Cumulative N Population'] / (df_actual_pred_probs.shape[0])\n",
    "    df_actual_pred_probs['Cumulative Perc Bad'] = df_actual_pred_probs['Cumulative N Bad'] / df_actual_pred_probs['y_actual'].sum()\n",
    "    df_actual_pred_probs['Cumulative Perc Good'] = df_actual_pred_probs['Cumulative N Good'] / (df_actual_pred_probs.shape[0] - df_actual_pred_probs['y_actual'].sum())\n",
    "\n",
    "    KS = max(df_actual_pred_probs['Cumulative Perc Bad'] - df_actual_pred_probs['Cumulative Perc Good'])\n",
    "    \n",
    "    return KS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KS coefficient on the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24890443314778865"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_test(y_test, y_pred_prob, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KS coefficient on the train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_train = logistic_reg.predict_proba(X_train)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2532086600268418"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_test(y_train, y_pred_prob_train, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks(data=None,target=None, prob=None):\n",
    "    data['target0'] = 1 - data[target]\n",
    "    data['bucket'] = pd.qcut(data[prob], 10)\n",
    "    grouped = data.groupby('bucket', as_index = False)\n",
    "    kstable = pd.DataFrame()\n",
    "    kstable['min_prob'] = grouped.min()[prob]\n",
    "    kstable['max_prob'] = grouped.max()[prob]\n",
    "    kstable['events'] = grouped.sum()[target]\n",
    "    kstable['nonevents'] = grouped.sum()['target0']\n",
    "    kstable = kstable.sort_values(by=\"min_prob\", ascending=False).reset_index(drop = True)\n",
    "    kstable['event_rate'] = (kstable.events / data[target].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['nonevent_rate'] = (kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['cum_eventrate']=(kstable.events / data[target].sum()).cumsum()\n",
    "    kstable['cum_noneventrate']=(kstable.nonevents / data['target0'].sum()).cumsum()\n",
    "    kstable['KS'] = np.round(kstable['cum_eventrate']-kstable['cum_noneventrate'], 3) * 100\n",
    "\n",
    "     #Formating\n",
    "    kstable['cum_eventrate']= kstable['cum_eventrate'].apply('{0:.2%}'.format)\n",
    "    kstable['cum_noneventrate']= kstable['cum_noneventrate'].apply('{0:.2%}'.format)\n",
    "    kstable.index = range(1,11)\n",
    "    kstable.index.rename('Decile', inplace=True)\n",
    "    pd.set_option('display.max_columns', 9)\n",
    "    print(kstable)\n",
    "    #Display KS\n",
    "    from colorama import Fore\n",
    "    print(Fore.RED + \"KS is \" + str(max(kstable['KS']))+\"%\"+ \" at decile \" + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))\n",
    "    return(kstable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
